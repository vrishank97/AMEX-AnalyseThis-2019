{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "leaderboard = pd.read_csv(\"leaderboard_dataset.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train[\"VAR21\"]\n",
    "X = train.drop([\"VAR21\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == 'object':\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(X[c].values) + list(test[c].values) + list(leaderboard[c].values)) \n",
    "        X[c] = lbl.transform(list(X[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))\n",
    "        leaderboard[c] = lbl.transform(list(leaderboard[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl = LabelEncoder() \n",
    "lbl.fit(list(y.values)) \n",
    "y = lbl.transform(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.09568+3.58267e-05\ttest-mlogloss:1.09582+2.29541e-05\n",
      "[50]\ttrain-mlogloss:0.989505+0.0014094\ttest-mlogloss:0.996191+0.00125144\n",
      "[100]\ttrain-mlogloss:0.9306+0.00187451\ttest-mlogloss:0.943169+0.0023004\n",
      "[150]\ttrain-mlogloss:0.895134+0.00215201\ttest-mlogloss:0.913224+0.00322606\n",
      "[200]\ttrain-mlogloss:0.87213+0.00231356\ttest-mlogloss:0.895548+0.00407053\n",
      "[250]\ttrain-mlogloss:0.856005+0.00246\ttest-mlogloss:0.884611+0.00459239\n",
      "[300]\ttrain-mlogloss:0.844014+0.00258351\ttest-mlogloss:0.87768+0.00508668\n",
      "[350]\ttrain-mlogloss:0.834707+0.00248425\ttest-mlogloss:0.873327+0.00539159\n",
      "[400]\ttrain-mlogloss:0.826983+0.00240359\ttest-mlogloss:0.870246+0.00556645\n",
      "[450]\ttrain-mlogloss:0.820524+0.00233567\ttest-mlogloss:0.86826+0.00570957\n",
      "[500]\ttrain-mlogloss:0.814665+0.00221058\ttest-mlogloss:0.86689+0.00582958\n",
      "[550]\ttrain-mlogloss:0.809282+0.00225323\ttest-mlogloss:0.865891+0.00584704\n",
      "[600]\ttrain-mlogloss:0.804306+0.00220314\ttest-mlogloss:0.86511+0.00592121\n",
      "[650]\ttrain-mlogloss:0.799675+0.00230723\ttest-mlogloss:0.864515+0.00598814\n",
      "[700]\ttrain-mlogloss:0.795205+0.00226606\ttest-mlogloss:0.864094+0.00598332\n",
      "[750]\ttrain-mlogloss:0.790977+0.00223074\ttest-mlogloss:0.863795+0.00605189\n",
      "[800]\ttrain-mlogloss:0.786981+0.00239081\ttest-mlogloss:0.863618+0.00609749\n",
      "[850]\ttrain-mlogloss:0.783157+0.00240738\ttest-mlogloss:0.863482+0.00610542\n",
      "[900]\ttrain-mlogloss:0.779417+0.00247683\ttest-mlogloss:0.863414+0.00613839\n",
      "[950]\ttrain-mlogloss:0.775727+0.00253961\ttest-mlogloss:0.863395+0.00616618\n",
      "[1000]\ttrain-mlogloss:0.772042+0.00248929\ttest-mlogloss:0.863343+0.00616211\n",
      "[1050]\ttrain-mlogloss:0.768394+0.00255056\ttest-mlogloss:0.863327+0.00613565\n",
      "[1100]\ttrain-mlogloss:0.764786+0.00257361\ttest-mlogloss:0.863314+0.00612779\n",
      "[1150]\ttrain-mlogloss:0.761247+0.00259874\ttest-mlogloss:0.863304+0.00612422\n",
      "num_boost_rounds=1112\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# prepare dict of params for xgboost to run with\n",
    "xgb_params = {\n",
    "    'n_trees': 700, \n",
    "    'eta': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.92,\n",
    "    'objective': 'multi:softmax',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'silent': 1,\n",
    "    'num_class' :3\n",
    "}\n",
    "\n",
    "# form DMatrices for Xgboost training\n",
    "dtrain = xgb.DMatrix(X, y)\n",
    "dtest = xgb.DMatrix(leaderboard)\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(xgb_params, \n",
    "                   dtrain, \n",
    "                   num_boost_round=1200, # increase to have better results (~700)\n",
    "                   verbose_eval=50,\n",
    "                   early_stopping_rounds=50\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print('num_boost_rounds=' + str(num_boost_rounds))\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "\n",
    "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
    "\n",
    "# make predictions and save results\n",
    "y_preds = model.predict(dtest)\n",
    "\n",
    "d = {'col1': leaderboard[\"VAR1\"], 'col2': [int(i) for i in y_preds]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df[\"col2\"][df[\"col2\"] == 0] = \"High\"\n",
    "df[\"col2\"][df[\"col2\"] == 1] = \"Low\"\n",
    "df[\"col2\"][df[\"col2\"] == 2] = \"Medium\"\n",
    "\n",
    "import shutil \n",
    "\n",
    "filename = \"Quant404_IITGuwahati_24\"\n",
    "df.to_csv(filename+'.csv', index=False, header=False)\n",
    "shutil.copyfile(\"Quant404_IITGuwahati_12.ipynb\", filename+\".ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# prepare dict of params for xgboost to run with\n",
    "xgb_params = {\n",
    "    'n_trees': 700, \n",
    "    'eta': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.93,\n",
    "    'objective': 'multi:softmax',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'silent': 1,\n",
    "    'num_class' :3\n",
    "}\n",
    "\n",
    "# form DMatrices for Xgboost training\n",
    "dtrain = xgb.DMatrix(X, y)\n",
    "dtest = xgb.DMatrix(leaderboard)\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(xgb_params, \n",
    "                   dtrain, \n",
    "                   num_boost_round=1200, # increase to have better results (~700)\n",
    "                   verbose_eval=50,\n",
    "                   early_stopping_rounds=50\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print('num_boost_rounds=' + str(num_boost_rounds))\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "\n",
    "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
    "\n",
    "# make predictions and save results\n",
    "y_preds = model.predict(dtest)\n",
    "\n",
    "d = {'col1': leaderboard[\"VAR1\"], 'col2': [int(i) for i in y_preds]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df[\"col2\"][df[\"col2\"] == 0] = \"High\"\n",
    "df[\"col2\"][df[\"col2\"] == 1] = \"Low\"\n",
    "df[\"col2\"][df[\"col2\"] == 2] = \"Medium\"\n",
    "\n",
    "import shutil \n",
    "\n",
    "filename = \"Quant404_IITGuwahati_25\"\n",
    "df.to_csv(filename+'.csv', index=False, header=False)\n",
    "shutil.copyfile(\"Quant404_IITGuwahati_23.ipynb\", filename+\".ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719362ece2a14f2abcc93ef5ca289e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #14 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #17 due to time out. Continuing to the next pipeline.\n"
     ]
    }
   ],
   "source": [
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
